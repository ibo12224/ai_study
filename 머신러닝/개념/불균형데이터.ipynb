{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2035e631",
   "metadata": {},
   "source": [
    "# **불균형 데이터(Imbalanced Data)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86698083",
   "metadata": {},
   "source": [
    "사기 거래 탐지(Fraud Detection)와 같은 **불균형 데이터(Imbalanced Data)** 문제는 머신러닝 모델 학습에 있어 매우 중요하며, 소수 클래스(예: 사기 거래)를 정확하게 예측하는 것이 핵심.\n",
    "\n",
    "불균형 데이터를 처리하는 방법은 크게 **데이터 레벨 접근(Data-Level)**, **알고리즘 레벨 접근(Algorithm-Level)**, 그리고 **평가 지표 수정**으로 나눌 수 있다.\n",
    "\n",
    "## 1. 데이터 레벨 접근 (Resampling Techniques)훈련 데이터셋의 클래스 분포를 물리적으로 조정하는 방법.\n",
    "\n",
    "* **오버샘플링 (Oversampling)**\n",
    "* **개념:** 소수 클래스의 데이터를 늘려 다수 클래스와 균형을 맞춥니다.\n",
    "* **단순 복제 (Random Oversampling):** 단순히 소수 클래스 샘플을 복사합니다. 과적합(Overfitting)의 위험이 있습니다.\n",
    "* **SMOTE (Synthetic Minority Over-sampling Technique):** 소수 클래스의 데이터와 그 주변의 k개 이웃 데이터를 사용하여 **가상의 새로운 합성 데이터**를 생성합니다. 단순 복제보다 일반화에 유리합니다.\n",
    "* **ADASYN:** SMOTE와 유사하지만, 학습하기 어려운(경계에 가까운) 소수 클래스 데이터에 더 많은 가중치를 두어 새로운 샘플을 생성합니다.\n",
    "\n",
    "\n",
    "* **언더샘플링 (Undersampling)**\n",
    "* **개념:** 다수 클래스의 데이터를 줄여 소수 클래스와 균형을 맞춥니다.\n",
    "* **단순 제거 (Random Undersampling):** 다수 클래스 샘플을 무작위로 제거합니다. **정보 손실**의 위험이 있습니다.\n",
    "* **Tomek Links, NearMiss:** 다수 클래스 중 소수 클래스와 경계선에 있거나 거리가 가까운 데이터를 선택적으로 제거하여 분류 경계를 명확하게 만듭니다.\n",
    "\n",
    "\n",
    "* **복합 샘플링 (Combined Sampling):**\n",
    "* 오버샘플링(예: SMOTE)과 언더샘플링(예: Tomek Links)을 조합하여 단점들을 보완.\n",
    "\n",
    "\n",
    "\n",
    "## 2. 알고리즘 레벨 접근 및 모델 조정데이터셋을 변경하지 않고 모델 학습 과정이나 예측 방식을 조정하는 방법.\n",
    "\n",
    "* **클래스 가중치 부여 (Class Weighting)**\n",
    "* 모델 학습 시, **소수 클래스의 오분류에 더 높은 패널티(가중치)**를 부여하여 모델이 소수 클래스 예측에 더 집중하도록 만듭니다. 많은 분류 알고리즘(예: `scikit-learn`의 `SVC`, `LogisticRegression`, 트리 기반 모델 등)에서 `class_weight='balanced'` 옵션을 지원합니다.\n",
    "\n",
    "\n",
    "* **앙상블 기법 (Ensemble Techniques)**\n",
    "* **랜덤 포레스트(Random Forest)**와 같은 트리 기반 모델이나 **AdaBoost**는 불균형 데이터에 비교적 강인한 성능을 보일 수 있습니다.\n",
    "* 불균형 데이터에 특화된 앙상블 기법(예: Balanced Bagging, EasyEnsemble)을 사용합니다.\n",
    "\n",
    "\n",
    "* **임계값 (Threshold) 조정**\n",
    "* 모델은 보통 0.5 이상의 예측 확률을 다수 클래스로 분류하지만, 소수 클래스 예측에 대한 민감도를 높이기 위해 임계값을 0.5보다 낮은 값(예: 0.2)으로 조정할 수 있습니다. 이를 통해 **재현율(Recall)**을 높이는 효과를 얻을 수 있습니다.\n",
    "\n",
    "\n",
    "* **이상 탐지 기법 (Anomaly Detection)**\n",
    "* 사기 거래 탐지처럼 불균형이 극심한 경우, 소수 클래스(사기)를 일반적인 분류 문제가 아닌 **이상치(Anomaly)**로 간주하고 **One-Class SVM**이나 **Isolation Forest**와 같은 이상 탐지 알고리즘을 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "## 3. 평가 지표 수정 (Evaluation Metrics)단순 **정확도(Accuracy)**는 다수 클래스만 잘 맞춰도 높게 나오기 때문에 불균형 데이터에서는 적절하지 않습니다. 소수 클래스의 예측 성능을 측정할 수 있는 지표를 사용해야 한다.\n",
    "\n",
    "* **정밀도 (Precision) 및 재현율 (Recall)**\n",
    "* **정밀도:** 모델이 '사기'라고 예측한 것 중 **실제로 사기인 비율**.\n",
    "* **재현율:** **실제 사기** 거래 중 모델이 '사기'라고 **정확하게 예측한 비율**. 사기 거래 탐지에서는 **재현율**을 높이는 것이 중요한 경우가 많습니다.\n",
    "\n",
    "\n",
    "* **F1-Score:** 정밀도와 재현율의 조화 평균으로, 두 지표의 균형 잡힌 성능을 보여줍니다.\n",
    "* **ROC-AUC / PR-AUC**\n",
    "* **ROC-AUC (Receiver Operating Characteristic - Area Under the Curve):** 분류 모델의 성능을 전반적으로 평가하는 지표.\n",
    "* **PR-AUC (Precision-Recall AUC):** 특히 불균형 데이터셋에서 ROC-AUC보다 더 유용한 평가 지표로 간주됩니다.\n",
    "\n",
    "\n",
    "\n",
    "사기 거래 탐지와 같은 경우, **소수 클래스(사기 거래)를 놓치지 않는 것(높은 재현율)**이 중요하므로, **SMOTE와 같은 샘플링 기법**을 적용하고, **클래스 가중치**를 부여하며, **재현율/F1-Score/PR-AUC**를 주요 평가 지표로 사용하는 전략이 일반적.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
