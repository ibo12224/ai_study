{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75081b8e",
   "metadata": {},
   "source": [
    "# 나이브 베이즈(Naive Bayes) \n",
    "\n",
    "## 1. 나이브 베이즈란?\n",
    "- **베이즈 정리**를 기반으로 한 **분류 알고리즘**  \n",
    "- 이름에서 **\"Naive(순진한)\"** 이 붙은 이유:  \n",
    "  ➡ 모든 **특성(Feature)** 들이 서로 **독립**이라고 가정하기 때문  \n",
    "- 간단하고 빠르며, 특히 **텍스트 분류(스팸 메일, 감성 분석)** 에 자주 사용됨\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 베이즈 정리 복습\n",
    "**베이즈 정리 공식**  \n",
    "\n",
    "$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$\n",
    "\n",
    "- $P(A|B)$ : **B가 주어졌을 때 A일 확률** (사후 확률)\n",
    "- $P(B|A)$ : **A일 때 B가 나올 확률** (가능도, Likelihood)\n",
    "- $P(A)$ : **A가 발생할 확률** (사전 확률)\n",
    "- $P(B)$ : **B가 발생할 확률** (정규화 상수)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 나이브 베이즈의 동작 원리\n",
    "1. **사전 확률** $P(\\text{클래스})$ 계산  \n",
    "2. **특징별 조건부 확률** $P(\\text{특징}|\\text{클래스})$ 계산  \n",
    "3. 모든 특징의 조건부 확률을 곱함 (독립 가정)  \n",
    "4. 가장 확률이 큰 클래스를 선택\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 나이브 베이즈 예시\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf2f92",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. 예시 상황\n",
    "- **단어 등장 횟수 표**  \n",
    "\n",
    "| 단어       | 스팸(Spam) | 정상(Ham) |\n",
    "|------------|-----------|----------|\n",
    "| 할인       | 4         | 1        |\n",
    "| 무료       | 3         | 1        |\n",
    "| 안녕하세요 | 1         | 5        |\n",
    "| 총 단어 수 | 8   | 7    |\n",
    "\n",
    "- **새로 받은 메일:** `\"무료 할인\"`\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 계산 목표\n",
    "우리는 이 메일이 **스팸일 확률**  \n",
    "즉, $P(\\text{스팸} \\mid \\text{무료, 할인})$ 을 구하고 싶음.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. 베이즈 정리에 따라 계산\n",
    "나이브 베이즈는 이렇게 계산함:\n",
    "\n",
    "$P(\\text{스팸} \\mid \\text{무료, 할인}) \\propto P(\\text{무료} \\mid \\text{스팸}) \\times P(\\text{할인} \\mid \\text{스팸}) \\times P(\\text{스팸})$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. 각 확률 계산\n",
    "1. **사전 확률** (P(스팸))  \n",
    "   - 전체 메일 중 스팸 비율이라고 가정 (여기서는 데이터가 없으니 50%로 가정)  \n",
    "   - $P(\\text{스팸}) = 0.5$\n",
    "\n",
    "2. **조건부 확률**  \n",
    "   - $P(\\text{무료} \\mid \\text{스팸}) = \\frac{\\text{스팸에서 '무료' 등장 횟수}}{\\text{스팸 전체 단어 수}} = \\frac{3}{8}$\n",
    "   - $P(\\text{할인} \\mid \\text{스팸}) = \\frac{4}{8}$\n",
    "\n",
    "---\n",
    "\n",
    "### 5. 스팸일 확률 계산 (비례값)\n",
    "$P(\\text{스팸} \\mid \\text{무료, 할인}) \\propto \\frac{3}{8} \\times \\frac{4}{8} \\times 0.5$\n",
    "\n",
    "$\\Rightarrow \\frac{3}{8} \\times \\frac{4}{8} \\times 0.5 = \\frac{12}{128} = 0.09375$\n",
    "\n",
    "---\n",
    "\n",
    "### 6. 정상(Ham)일 확률 계산\n",
    "같은 방식으로:\n",
    "\n",
    "$P(\\text{무료} \\mid \\text{정상}) = \\frac{1}{7}$  \n",
    "$P(\\text{할인} \\mid \\text{정상}) = \\frac{1}{7}$  \n",
    "$P(\\text{정상}) = 0.5$\n",
    "\n",
    "$P(\\text{정상} \\mid \\text{무료, 할인}) \\propto \\frac{1}{7} \\times \\frac{1}{7} \\times 0.5 = \\frac{1}{98} \\times 0.5 \\approx 0.0051$\n",
    "\n",
    "---\n",
    "\n",
    "### 7. 비교 후 결론\n",
    "- 스팸: $0.09375$\n",
    "- 정상: $0.0051$\n",
    "\n",
    "➡ 스팸 확률이 훨씬 높으므로 `\"무료 할인\"` 메일은 **스팸**으로 분류.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. 핵심 요약\n",
    "> 나이브 베이즈는 **각 단어가 해당 클래스에서 나올 확률을 곱**해서  \n",
    "> 가장 큰 확률을 가진 클래스를 선택한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124679a",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 장점 & 단점\n",
    " **장점**\n",
    "- 구현이 쉽고 계산이 빠름\n",
    "- 적은 데이터로도 잘 동작\n",
    "- 텍스트 분류에 강점\n",
    "\n",
    " **단점**\n",
    "- 특성들이 서로 독립이라는 가정이 현실과 다를 수 있음\n",
    "- 연속형 변수 처리 시 가정(예: 가우시안 분포)이 필요\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24742564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 원본 데이터 ---\n",
      "   무료  할인  쿠폰 label\n",
      "0   1   1   1  spam\n",
      "1   0   0   0   ham\n",
      "2   1   0   0  spam\n",
      "3   0   1   0  spam\n",
      "\n",
      "--- 새 메일 예측 결과 ---\n",
      "새 메일('무료 할인')의 예측 레이블: spam\n",
      "레이블 순서: ['ham' 'spam']\n",
      "예측 확률 (spam/ham): [0.10258515 0.89741485]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. 데이터 준비 (R의 data.frame에 해당)\n",
    "# 데이터셋 생성\n",
    "data = pd.DataFrame({\n",
    "    '무료': [1, 0, 1, 0],\n",
    "    '할인': [1, 0, 0, 1],\n",
    "    '쿠폰': [1, 0, 0, 0],\n",
    "    'label': [\"spam\", \"ham\", \"spam\", \"spam\"]\n",
    "})\n",
    "\n",
    "print(\"--- 원본 데이터 ---\")\n",
    "print(data)\n",
    "\n",
    "# 특성(X)과 타겟(y) 분리\n",
    "X = data[['무료', '할인', '쿠폰']]\n",
    "y = data['label']\n",
    "\n",
    "# 2. Naive Bayes 모델 생성 및 학습 (R의 naiveBayes()에 해당)\n",
    "# 이진 특성(0 또는 1)에 적합한 Bernoulli Naive Bayes 사용\n",
    "model = BernoulliNB()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y)\n",
    "\n",
    "# 3. 새 메일에 대한 예측 (R의 predict()에 해당)\n",
    "# 새 메일: \"무료 할인\" -> 무료=1, 할인=1, 쿠폰=0\n",
    "test_data = pd.DataFrame({\n",
    "    '무료': [1],\n",
    "    '할인': [1],\n",
    "    '쿠폰': [0]\n",
    "})\n",
    "\n",
    "# 예측 수행\n",
    "prediction = model.predict(test_data)\n",
    "# 확률 예측도 확인 가능\n",
    "probabilities = model.predict_proba(test_data)\n",
    "\n",
    "print(\"\\n--- 새 메일 예측 결과 ---\")\n",
    "print(f\"새 메일('무료 할인')의 예측 레이블: {prediction[0]}\")\n",
    "# 'spam'과 'ham'의 인덱스를 확인하여 확률과 매칭\n",
    "# model.classes_를 확인하여 순서 알 수 있음\n",
    "print(f\"레이블 순서: {model.classes_}\") \n",
    "print(f\"예측 확률 (spam/ham): {probabilities[0]}\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
