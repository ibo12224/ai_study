{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88b9818a",
   "metadata": {},
   "source": [
    "##  경사 하강법 (Gradient Descent) 이란?\n",
    "\n",
    "경사 하강법은 **기계 학습(Machine Learning)** 모델을 훈련시키는 데 사용되는 가장 기본적인 **최적화 알고리즘** 중 하나입니다.\n",
    "\n",
    "핵심 목표는 모델의 **손실 함수(Loss Function) 값**을 **최소화**하는 **최적의 매개변수 (가중치 $W$와 편향 $b$)**를 찾는 것입니다. 손실 함수는 모델의 예측이 실제 값과 얼마나 차이가 나는지를 측정합니다. 이 값이 작을수록 모델의 성능이 좋다는 의미입니다.\n",
    "\n",
    "---\n",
    "\n",
    "##  작동 원리\n",
    "\n",
    "경사 하강법은 마치 **산(손실 함수)**에서 **가장 낮은 지점(최소 손실)**을 찾기 위해 발을 딛는 것과 같습니다.\n",
    "\n",
    "1.  **시작점 설정**: 모델의 매개변수($W, b$)를 임의의 값으로 **초기화**합니다.\n",
    "2.  **경사 (Gradient) 계산**: 현재 위치($W, b$)에서 손실 함수의 **기울기 (경사, Gradient)**를 계산합니다. 기울기는 해당 지점에서 손실 함수 값이 가장 **가파르게 증가**하는 방향과 크기를 나타냅니다.\n",
    "3.  **하강 방향 결정**: 손실을 최소화해야 하므로, 기울기의 **반대 방향**($-$)으로 이동합니다. 즉, 손실 함수가 **가장 가파르게 감소**하는 방향으로 이동합니다.\n",
    "4.  **매개변수 업데이트**: 계산된 경사에 **학습률 (Learning Rate, $\\alpha$)**을 곱한 값만큼 매개변수를 업데이트합니다.\n",
    "    * $$W_{new} = W_{old} - \\alpha \\cdot \\frac{\\partial L}{\\partial W}$$\n",
    "    * $$b_{new} = b_{old} - \\alpha \\cdot \\frac{\\partial L}{\\partial b}$$\n",
    "    * 여기서 $L$은 손실 함수, $\\frac{\\partial L}{\\partial W}$는 $W$에 대한 손실 함수의 편미분 (경사)입니다.\n",
    "\n",
    "5.  **반복**: 이 과정을 손실 함수 값이 더 이상 크게 감소하지 않을 때까지 또는 정해진 **반복 횟수 (Epoch)**만큼 반복합니다.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##  주요 하이퍼파라미터\n",
    "\n",
    "### 1. 학습률 ($\\alpha$, Learning Rate)\n",
    "\n",
    "* **정의**: 매개변수를 업데이트할 때 한 번에 이동하는 **보폭**을 결정하는 값입니다.\n",
    "* **중요성**:\n",
    "    * **너무 크면**: 최솟값을 건너뛰고 발산할 수 있습니다 (Overshooting).\n",
    "    * **너무 작으면**: 최솟값에 도달하는 데 시간이 너무 오래 걸리거나 지역 최솟값(Local Minimum)에 갇힐 수 있습니다.\n",
    "\n",
    "### 2. 반복 횟수 (Epoch)\n",
    "\n",
    "* **정의**: 전체 훈련 데이터셋을 사용하여 모델을 훈련시키는 횟수입니다.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-16-gradient_descent/pic4.png'>\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a062b",
   "metadata": {},
   "source": [
    "##  경사 하강법의 종류\n",
    "\n",
    "데이터를 사용하는 방식에 따라 다음과 같이 세 가지 주요 유형으로 나뉩니다.\n",
    "\n",
    "| 유형 | 데이터 사용 방식 | 장점 | 단점 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **배치 경사 하강법 (Batch GD)** | 전체 훈련 데이터셋 $\\text{(N)}$을 한 번에 사용 | 안정적이고 수렴이 보장됨 | 계산 비용이 매우 높음 (대규모 데이터) |\n",
    "| **확률적 경사 하강법 (Stochastic GD, SGD)** | **하나의** 데이터 샘플 $\\text{(1)}$마다 매개변수 업데이트 | 빠르고 메모리 효율적 | 손실 함수의 변동성이 크고 불안정함 |\n",
    "| **미니 배치 경사 하강법 (Mini-Batch GD)** | **미니 배치 $\\text{(k)}$** 크기의 데이터셋을 사용 $\\text{(1 < k < N)}$ | 속도와 안정성의 균형이 좋음 (가장 널리 사용) | 미니 배치 크기를 설정해야 함 |\n",
    "\n",
    "**미니 배치 경사 하강법**이 실제로 가장 많이 사용됩니다.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
